{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load and preprocess the dataset\n",
    "class LemmatizerDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = []\n",
    "        with open(data_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                # Split line and validate format\n",
    "                parts = line.strip().split('-')\n",
    "                if len(parts) == 2:  # Ensure there are exactly two parts\n",
    "                    self.data.append(parts)\n",
    "                else:\n",
    "                    print(f\"Skipping invalid line: {line.strip()}\")\n",
    "\n",
    "        self.char_to_idx, self.idx_to_char = self.build_vocab()\n",
    "\n",
    "    def build_vocab(self):\n",
    "        chars = set(\"\".join(word for pair in self.data for word in pair))  # Collect unique characters\n",
    "        char_to_idx = {char: idx + 1 for idx, char in enumerate(sorted(chars))}  # Start from index 1\n",
    "        char_to_idx['<pad>'] = 0  # Padding token at index 0\n",
    "        char_to_idx['<sos>'] = len(char_to_idx)  # Sequentially assign <sos>\n",
    "        char_to_idx['<eos>'] = len(char_to_idx)  # Sequentially assign <eos>\n",
    "        \n",
    "        idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "        # Debug prints\n",
    "        print(\"Vocabulary:\", char_to_idx)\n",
    "        print(\"Number of unique characters:\", len(char_to_idx))\n",
    "        print(\"Max index assigned:\", max(char_to_idx.values()))\n",
    "        \n",
    "        # Adjust the assertion\n",
    "        assert max(char_to_idx.values()) == len(char_to_idx) - 1, \"Vocabulary size mismatch\"\n",
    "        import json\n",
    "        # Save character mappings\n",
    "        with open(\"char_to_idx.json\", \"w\") as f:\n",
    "            json.dump(char_to_idx, f)\n",
    "\n",
    "        with open(\"idx_to_char.json\", \"w\") as f:\n",
    "            json.dump(idx_to_char, f)\n",
    "        return char_to_idx, idx_to_char\n",
    "\n",
    "    def encode(self, word):\n",
    "        return [self.char_to_idx['<sos>']] + [self.char_to_idx[char] for char in word] + [self.char_to_idx['<eos>']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_word, target_word = self.data[idx]\n",
    "        input_encoded = self.encode(input_word)\n",
    "        target_encoded = self.encode(target_word)\n",
    "        # Debug print to validate encoding\n",
    "        # print(f\"Input Word: {input_word}, Encoded: {input_encoded}\")\n",
    "        return torch.tensor(input_encoded, dtype=torch.long), torch.tensor(target_encoded, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Collate function to pad sequences in the batch\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data_file = \"Huge_Augmented_Dataset.txt\"\n",
    "dataset = LemmatizerDataset(data_file)\n",
    "# Splitting the dataset into training and validation sets\n",
    "train_data, val_data = train_test_split(list(range(len(dataset))), test_size=0.1, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_data)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_data)\n",
    "\n",
    "# DataLoaders with collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_lengths):\n",
    "        embedded = self.dropout(self.embedding(x))  # Shape: (batch_size, seq_len, embed_dim)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, src_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "\n",
    "        # Combine forward and backward states for hidden and cell\n",
    "        hidden = self._combine_directions(hidden)\n",
    "        cell = self._combine_directions(cell)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "    def _combine_directions(self, states):\n",
    "        # Combine forward and backward states\n",
    "        num_layers = states.size(0) // 2\n",
    "        batch_size = states.size(1)\n",
    "        hidden_dim = states.size(2)\n",
    "        combined = states.view(num_layers, 2, batch_size, hidden_dim).mean(dim=1)\n",
    "        return combined  # Shape: (num_layers, batch_size, hidden_dim)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim, dec_hidden_dim)\n",
    "        self.v = nn.Parameter(torch.rand(dec_hidden_dim))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = torch.sum(self.v * energy, dim=2)\n",
    "        return torch.softmax(attention, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, enc_hidden_dim, dec_hidden_dim, n_layers, attention, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM((enc_hidden_dim * 2) + embed_dim, dec_hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim + embed_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden, cell, encoder_outputs):\n",
    "        x = x.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        attention_weights = attention_weights.unsqueeze(1)\n",
    "        weighted = torch.bmm(attention_weights, encoder_outputs)\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))\n",
    "        prediction = self.fc_out(torch.cat((output.squeeze(1), weighted.squeeze(1), embedded.squeeze(1)), dim=1))\n",
    "        return prediction, hidden, cell, attention_weights\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[1]\n",
    "        batch_size = src.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        src_lengths = (src != 0).sum(dim=1)  # Calculate sequence lengths\n",
    "\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_lengths)\n",
    "\n",
    "        input = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell, _ = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[:, t, :] = output\n",
    "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
    "            input = trg[:, t] if teacher_force else output.argmax(1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "INPUT_DIM = len(dataset.char_to_idx)\n",
    "OUTPUT_DIM = len(dataset.char_to_idx)\n",
    "EMBED_DIM = 64\n",
    "ENC_HIDDEN_DIM = 128\n",
    "DEC_HIDDEN_DIM = 128\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 3\n",
    "\n",
    "import json\n",
    "\n",
    "# Save character mappings\n",
    "with open(\"char_to_idx.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(dataset.char_to_idx, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(\"idx_to_char.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(dataset.idx_to_char, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Save the model architecture configuration\n",
    "config = {\n",
    "    \"INPUT_DIM\": INPUT_DIM,\n",
    "    \"OUTPUT_DIM\": OUTPUT_DIM,\n",
    "    \"EMBED_DIM\": EMBED_DIM,\n",
    "    \"ENC_HIDDEN_DIM\": ENC_HIDDEN_DIM,\n",
    "    \"DEC_HIDDEN_DIM\": DEC_HIDDEN_DIM,\n",
    "    \"N_LAYERS\": N_LAYERS,\n",
    "    \"DROPOUT\": DROPOUT,\n",
    "}\n",
    "with open(\"model_config.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(config, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "attention = Attention(ENC_HIDDEN_DIM, DEC_HIDDEN_DIM)\n",
    "encoder = Encoder(INPUT_DIM, EMBED_DIM, ENC_HIDDEN_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "decoder = Decoder(OUTPUT_DIM, EMBED_DIM, ENC_HIDDEN_DIM, DEC_HIDDEN_DIM, N_LAYERS, attention, DROPOUT).to(device)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function: Calculate accuracy\n",
    "def calculate_accuracy(predictions, targets, pad_idx=0):\n",
    "    predictions = predictions.argmax(dim=1)  # Argmax over vocab dimension\n",
    "    mask = targets != pad_idx  # Mask padding tokens\n",
    "    correct = (predictions == targets) & mask  # Compare only non-padding tokens\n",
    "    return correct.sum().item() / mask.sum().item()\n",
    "\n",
    "\n",
    "# Training and validation function\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss, epoch_acc = 0, 0\n",
    "    for src, trg in loader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)  # Ignore <sos>\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        acc = calculate_accuracy(output, trg)  # Pass reshaped tensors\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "def evaluate_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss, epoch_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg in loader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            acc = calculate_accuracy(output.view(-1, OUTPUT_DIM), trg)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "# Training loop\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "best_val_loss = float(\"inf\")\n",
    "MODEL_SAVE_PATH = \"best_lemmatizer_model_2.pth\"\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate_epoch(model, val_loader, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "MODEL_SAVE_PATH = \"best_lemmatizer_model_2.pth\"\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "def predict_lemmatized_word(model, word, dataset):\n",
    "    \"\"\"\n",
    "    Predict the root form of a given word using the trained model.\n",
    "    Args:\n",
    "        model: Trained Seq2Seq model.\n",
    "        word: Input word as a string.\n",
    "        dataset: Instance of LemmatizerDataset for encoding and decoding.\n",
    "    Returns:\n",
    "        Predicted root word as a string.\n",
    "    \"\"\"\n",
    "    # Encode the input word\n",
    "    encoded_word = torch.tensor([dataset.encode(word)], dtype=torch.long).to(device)\n",
    "\n",
    "    # Pass through the encoder\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = model.encoder(encoded_word, (encoded_word != 0).sum(dim=1))\n",
    "        input_token = torch.tensor([dataset.char_to_idx[\"<sos>\"]], dtype=torch.long).to(device)\n",
    "\n",
    "        # Decode the output\n",
    "        predicted_word = []\n",
    "        for _ in range(50):  # Max output length\n",
    "            output, hidden, cell, _ = model.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "            token_idx = output.argmax(1).item()\n",
    "            if token_idx == dataset.char_to_idx[\"<eos>\"]:\n",
    "                break\n",
    "            predicted_word.append(dataset.idx_to_char[token_idx])\n",
    "            input_token = torch.tensor([token_idx], dtype=torch.long).to(device)\n",
    "\n",
    "    return \"\".join(predicted_word)\n",
    "\n",
    "# Test with example words\n",
    "test_input = \"\"\n",
    "test_words = test_input.split()\n",
    "predicted_list = []\n",
    "for word in test_words:\n",
    "    predicted_root = predict_lemmatized_word(model, word, dataset)\n",
    "    predicted_list.append(predicted_root)\n",
    "print(predicted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
